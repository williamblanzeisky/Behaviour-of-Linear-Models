{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5HExLQrE4ZxR"
   },
   "source": [
    "<h1><font color='blue'> 8E and 8F: Finding the Probability P(Y==1|X)</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4LuKrFzC4ZxV"
   },
   "source": [
    "<h2><font color='Geen'> 8E: Implementing Decision Function of SVM RBF Kernel</font></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1wES-wWN4ZxX"
   },
   "source": [
    "<font face=' Comic Sans MS' size=3>After we train a kernel SVM model, we will be getting support vectors and their corresponsing coefficients $\\alpha_{i}$\n",
    "\n",
    "Check the documentation for better understanding of these attributes: \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "<img src='https://i.imgur.com/K11msU4.png' width=500>\n",
    "\n",
    "As a part of this assignment you will be implementing the ```decision_function()``` of kernel SVM, here decision_function() means based on the value return by ```decision_function()``` model will classify the data point either as positive or negative\n",
    "\n",
    "Ex 1: In logistic regression After traning the models with the optimal weights $w$ we get, we will find the value $\\frac{1}{1+\\exp(-(wx+b))}$, if this value comes out to be < 0.5 we will mark it as negative class, else its positive class\n",
    "\n",
    "Ex 2: In Linear SVM After traning the models with the optimal weights $w$ we get, we will find the value of $sign(wx+b)$, if this value comes out to be -ve we will mark it as negative class, else its positive class.\n",
    "\n",
    "Similarly in Kernel SVM After traning the models with the coefficients $\\alpha_{i}$ we get, we will find the value of \n",
    "$sign(\\sum_{i=1}^{n}(y_{i}\\alpha_{i}K(x_{i},x_{q})) + intercept)$, here $K(x_{i},x_{q})$ is the RBF kernel. If this value comes out to be -ve we will mark $x_{q}$ as negative class, else its positive class.\n",
    "\n",
    "RBF kernel is defined as: $K(x_{i},x_{q})$ = $exp(-\\gamma ||x_{i} - x_{q}||^2)$\n",
    "\n",
    "For better understanding check this link: https://scikit-learn.org/stable/modules/svm.html#svm-mathematical-formulation\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z830CfMk4Zxa"
   },
   "source": [
    "## Task E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MuBxHiCQ4Zxc"
   },
   "source": [
    "> 1. Split the data into $X_{train}$(60), $X_{cv}$(20), $X_{test}$(20)\n",
    "\n",
    "> 2. Train $SVC(gamma=0.001, C=100.)$ on the ($X_{train}$, $y_{train}$)\n",
    "\n",
    "> 3. Get the decision boundry values $f_{cv}$ on the $X_{cv}$ data  i.e. ` `$f_{cv}$ ```= decision_function(```$X_{cv}$```)```  <font color='red'>you need to implement this decision_function()</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fCgMNEvI4Zxf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ANUNIqCe4Zxn"
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=5000, n_features=5, n_redundant=2,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "x, x_test, y, y_test = train_test_split (X,y, test_size=0.2, train_size=0.8 )\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(x,y,test_size = 0.25, train_size =0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=7, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(gamma = 0.001, C=100, random_state = 7)\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.57463800e+00, -1.82232960e+00, -2.65223514e+00, -2.62951012e+00,\n",
       "       -3.55136263e+00,  1.53082124e+00, -1.93158819e+00,  1.71616352e+00,\n",
       "       -3.24615433e+00,  1.75518204e+00, -1.92898337e+00,  9.29804561e-01,\n",
       "       -2.28326203e+00, -3.47104530e+00, -4.32849183e+00, -2.36488835e+00,\n",
       "        1.75084839e+00,  2.27457941e+00,  1.85652750e+00,  1.90366607e+00,\n",
       "       -1.14806849e-01, -3.27193926e+00, -2.30867747e+00, -3.02098803e+00,\n",
       "       -1.96542611e+00, -4.19181958e+00,  1.32367762e+00, -2.93461272e+00,\n",
       "        2.29102600e-01, -3.04023069e+00,  1.07897533e+00, -2.96276200e+00,\n",
       "       -2.92328222e+00, -1.99178121e+00, -2.32860913e-01,  3.85018521e-01,\n",
       "       -1.70072224e+00,  1.66726145e+00, -3.41951275e+00,  1.61539505e+00,\n",
       "       -3.44192309e+00,  2.23479270e+00, -1.74239380e+00,  1.14387877e+00,\n",
       "       -2.68917459e+00,  1.25972795e+00, -1.70527396e+00, -3.14112465e+00,\n",
       "        1.62461022e+00,  1.69315782e+00,  1.06685386e+00, -2.99349347e+00,\n",
       "       -1.94300419e+00,  2.04753172e+00, -2.38344528e+00, -2.19628646e+00,\n",
       "       -3.62315610e-01, -1.30200371e+00, -2.88006032e+00, -8.19825384e-01,\n",
       "        2.41659402e+00, -1.60915516e+00, -3.98486518e+00, -2.24717402e+00,\n",
       "        1.82436443e+00,  3.41859992e+00,  1.40179639e+00, -2.56640761e+00,\n",
       "       -2.51409819e+00,  5.11747982e-01, -3.44712087e+00, -1.83135321e+00,\n",
       "        1.55546432e+00, -3.15146914e+00, -2.48317493e+00, -4.24635268e+00,\n",
       "       -1.01659159e-01, -2.81344171e+00, -3.51658262e+00, -3.24556274e+00,\n",
       "        1.28601107e+00,  2.14046365e-01, -6.03294450e-01, -2.27941583e+00,\n",
       "       -7.47798331e-01,  1.02606120e+00, -2.37400989e+00, -3.50109581e+00,\n",
       "       -3.42829286e+00,  7.99885388e-01, -1.85608799e+00, -4.09306379e+00,\n",
       "       -1.79363601e+00, -3.32393350e+00, -3.63649014e+00, -4.75842386e-01,\n",
       "       -7.91513890e-01, -2.53224616e+00, -3.09277750e+00, -2.65953187e+00,\n",
       "        7.31179403e-01, -2.09051845e+00,  1.22043784e+00, -2.85193302e+00,\n",
       "        9.03891641e-01, -1.90030107e+00, -1.33387197e+00, -3.60209572e+00,\n",
       "        2.10089860e+00,  1.79431205e+00, -3.16663505e+00,  2.70856301e+00,\n",
       "       -3.68721045e+00,  3.90990534e-01, -8.19796607e-01, -2.97995859e+00,\n",
       "       -2.94920970e+00, -2.72265064e+00, -3.22389422e+00, -2.94791837e+00,\n",
       "       -4.41889769e+00, -3.07514172e+00, -2.59641406e+00, -1.76239503e+00,\n",
       "       -2.28399706e+00, -4.40884095e+00, -2.03646624e+00,  2.62482995e+00,\n",
       "        1.42545770e+00, -1.08786198e+00,  3.78690126e-01, -3.45406325e+00,\n",
       "       -4.00887675e+00, -2.95456439e+00,  2.00149119e+00,  1.69759315e+00,\n",
       "       -3.42912928e+00, -1.75287506e+00, -2.84780948e+00, -2.90552886e+00,\n",
       "       -2.22455482e+00,  1.76882484e+00,  1.90448851e+00, -2.30863309e+00,\n",
       "       -4.04784083e+00,  2.03687926e+00, -2.75439094e+00, -2.10838803e+00,\n",
       "       -5.10247631e-02, -5.15373338e-01,  1.88821213e+00,  1.74275025e+00,\n",
       "       -2.55380037e+00, -2.45230240e+00, -2.04085967e+00, -2.75952470e+00,\n",
       "       -1.85610886e+00, -8.00880086e-02,  1.74606877e+00,  1.81579474e+00,\n",
       "       -2.25554961e+00,  1.22436283e-01, -1.08543106e+00, -2.56983227e+00,\n",
       "       -3.05321412e+00,  1.80472237e+00, -3.16244134e+00,  2.05565305e+00,\n",
       "       -2.23534434e+00, -1.55334065e+00, -6.64626314e+00, -2.59280374e+00,\n",
       "       -2.27009469e-01, -1.13575946e-01, -3.28919583e+00, -1.69253234e+00,\n",
       "       -2.02261735e+00, -3.88367192e-01, -4.54555393e+00, -2.82768208e+00,\n",
       "        1.17928591e+00,  8.07102014e-01, -1.86037838e+00,  9.28905167e-01,\n",
       "        6.13032839e-01,  2.09573602e+00,  9.71148397e-01, -3.65933467e+00,\n",
       "       -8.30721384e-01,  1.35782561e+00,  7.89890636e-01, -2.27116233e+00,\n",
       "       -3.17208094e+00,  1.81577884e+00, -2.12701345e+00, -2.37757661e+00,\n",
       "        1.83791520e+00, -3.23501914e+00, -8.81159001e-01, -4.07242756e+00,\n",
       "        1.95735701e+00, -2.66753566e-01, -1.66385236e+00,  1.72416976e+00,\n",
       "       -3.72910233e+00,  2.59509398e-01,  3.48013672e+00, -1.44588039e+00,\n",
       "        2.05286427e+00, -4.17978783e+00,  8.77213088e-01, -2.52569130e+00,\n",
       "       -6.08074556e-01, -3.60678900e+00, -3.19911903e+00,  1.46604166e+00,\n",
       "       -2.43148760e-01,  3.27842807e-02, -2.03731856e+00,  2.69817452e-01,\n",
       "       -1.69293651e+00,  2.21902605e+00, -2.94305662e+00, -6.81857833e-01,\n",
       "       -2.11199566e+00, -1.74163319e+00,  6.36757971e-01, -2.04722945e+00,\n",
       "        1.69271746e+00, -2.94690610e+00, -1.42138312e+00, -3.22087482e+00,\n",
       "        2.89310379e+00, -3.06763830e+00, -4.13245075e+00,  1.08851913e+00,\n",
       "       -2.52281648e+00,  2.15932000e+00, -2.28362762e+00,  5.13892690e-01,\n",
       "       -2.05339050e+00, -2.83518355e+00, -2.27123281e+00,  2.10404959e+00,\n",
       "       -2.14463777e+00, -1.69666676e+00, -1.09800140e+00,  9.97310834e-01,\n",
       "        1.25583180e+00, -1.67705556e+00,  1.03167167e+00, -1.62867410e+00,\n",
       "        5.40194331e-01, -1.49769687e+00, -2.71233535e-01,  1.51151929e+00,\n",
       "       -2.66794109e+00,  2.11759729e+00, -3.92819017e+00, -7.76735398e-01,\n",
       "        1.22619437e+00, -2.98539660e+00, -1.33361845e+00, -3.16679864e+00,\n",
       "        7.44316449e-01,  1.69663073e+00,  1.46947627e+00, -1.82129809e+00,\n",
       "        1.83274461e+00,  1.99620609e+00, -2.64979811e+00, -2.16414026e-01,\n",
       "       -3.29635822e+00, -2.44556914e+00, -1.92851139e+00,  1.74163285e+00,\n",
       "       -3.18529111e+00, -2.75812644e+00, -2.70669195e+00, -6.88179854e+00,\n",
       "        1.10392893e+00, -3.01508227e+00, -2.46039354e+00, -2.89777097e+00,\n",
       "       -3.05515787e+00, -3.44249257e+00, -1.32652358e+00,  1.25038143e+00,\n",
       "        1.69035897e+00,  1.99892119e-02, -2.20611084e+00, -3.32332510e+00,\n",
       "        1.13503126e+00,  1.28561437e+00,  1.45846868e+00, -3.17355173e+00,\n",
       "        1.66189619e+00,  1.69418020e+00, -2.22745829e+00, -4.02890078e+00,\n",
       "       -2.25933302e+00, -2.46709359e+00, -2.53303246e+00, -2.72257530e+00,\n",
       "       -3.72841323e+00, -4.08904008e+00,  7.14917958e-01,  9.01089391e-01,\n",
       "       -1.70610495e+00,  1.18306580e+00, -4.05270385e+00,  2.92211120e-01,\n",
       "        6.21924085e-01,  7.44335710e-01, -2.59168625e+00, -2.34809103e+00,\n",
       "       -1.85146009e+00, -1.15698448e+00, -2.42589857e+00, -1.58458148e+00,\n",
       "       -4.48662763e+00, -1.96174695e+00, -1.13719016e+00, -7.23011894e-01,\n",
       "        2.05671325e+00, -2.49436943e+00, -2.97944860e+00, -2.71353137e+00,\n",
       "       -2.43711635e+00, -1.59478903e+00, -4.06089083e-01, -2.11083389e+00,\n",
       "        1.26096053e+00, -1.53165470e+00,  1.03168798e+00,  1.86261827e+00,\n",
       "       -2.21761542e+00, -8.14069860e-01,  1.96784306e-01, -2.17324090e+00,\n",
       "       -3.04507168e+00, -1.75425007e+00, -4.00350544e+00, -2.00137029e+00,\n",
       "       -4.14233974e-01, -3.32281021e+00,  1.93597480e+00,  1.45901880e+00,\n",
       "       -2.06950665e+00, -3.02890101e+00,  1.64799786e+00,  1.57373048e+00,\n",
       "       -1.75393383e+00, -1.85179572e+00, -3.11458121e+00, -4.28231865e+00,\n",
       "       -3.91718151e+00, -2.48290596e+00, -1.65378020e+00, -2.43633141e+00,\n",
       "        1.35334067e+00, -2.07676071e+00, -2.68969393e+00,  1.50339385e+00,\n",
       "       -4.01580168e+00, -5.77485919e-02,  2.34961199e+00, -1.12334868e+00,\n",
       "       -1.90822495e+00,  1.34598083e+00, -3.27868493e+00, -2.43549393e+00,\n",
       "        1.92253021e+00, -2.05487975e+00, -3.04787623e-01,  4.12545539e-01,\n",
       "       -3.34237275e+00, -3.10222040e+00, -2.09837629e+00,  1.78915431e+00,\n",
       "       -2.53700802e+00, -3.74106095e-01,  3.58138538e-01,  4.07599941e-01,\n",
       "        3.68049798e-01, -1.65280340e+00,  1.03009176e+00, -1.38545684e+00,\n",
       "       -3.86824656e+00, -1.67954384e+00, -2.02786800e+00, -1.12455725e+00,\n",
       "       -3.00575222e+00,  2.68180538e+00, -2.20274814e+00, -2.73343659e+00,\n",
       "       -4.80492025e+00, -3.59901791e+00, -2.12743572e+00, -3.77597507e+00,\n",
       "        1.54960750e+00, -2.57488528e+00, -2.50619700e+00, -2.04777416e+00,\n",
       "       -2.99710690e-01,  1.26236667e+00, -2.18261457e+00,  1.61586006e+00,\n",
       "       -2.93960302e+00, -1.92143714e+00, -2.73324327e-01, -2.92405282e+00,\n",
       "        2.24924018e+00,  2.95459600e+00, -2.73714282e+00, -8.17691232e-01,\n",
       "       -2.38794790e+00,  1.64434625e+00,  2.42311343e-01,  1.37075558e+00,\n",
       "       -1.73243516e+00,  1.56167475e+00, -3.01500618e+00, -3.15785772e+00,\n",
       "       -5.33298300e-01,  1.26229260e+00,  1.64477177e+00,  2.01583957e-01,\n",
       "       -4.17859942e+00, -4.72876313e+00,  1.45673599e+00,  5.94202220e-02,\n",
       "        4.82929546e-01, -1.55434041e+00, -5.88321377e-01, -1.83860225e+00,\n",
       "        1.41694976e+00,  2.33112492e-01, -2.75499747e-01, -2.58333547e+00,\n",
       "       -3.54736791e+00, -8.42244026e-01, -3.38431201e+00, -3.33208894e+00,\n",
       "       -3.79832272e+00, -4.99313241e-01,  1.56257079e+00, -2.46002411e+00,\n",
       "        1.68505786e+00, -1.55595751e+00, -5.58598277e-01,  1.93694749e+00,\n",
       "        7.09320710e-01, -2.95240063e+00, -7.60345979e-01,  1.67705865e+00,\n",
       "       -1.99754852e+00, -3.62103941e+00, -5.46812645e-03, -8.85535970e-01,\n",
       "        7.60474310e-01, -2.41986570e+00,  2.36260990e+00,  2.00550158e+00,\n",
       "        1.66358439e+00, -1.93649932e+00, -2.29995511e+00,  1.17591486e+00,\n",
       "        9.52003533e-02, -1.80591786e+00, -3.15320026e+00, -2.24814852e+00,\n",
       "       -7.76256256e-02, -3.05377786e+00, -1.86688771e+00, -1.67436996e+00,\n",
       "       -2.43291890e+00, -9.67773166e-01, -1.42487539e+00, -2.92329355e+00,\n",
       "       -3.58736927e+00, -1.16564341e+00, -3.05926713e+00, -2.83295810e+00,\n",
       "       -2.64769458e+00, -3.07857572e+00, -2.53814048e+00,  5.98228072e-01,\n",
       "       -2.87539471e+00,  9.98310491e-01, -2.78715026e+00, -1.05197072e+00,\n",
       "       -1.39959853e+00, -1.93092720e+00, -3.89221464e+00, -2.34055304e+00,\n",
       "       -4.12440823e+00,  1.01716641e+00, -2.56998652e+00, -2.01389211e+00,\n",
       "       -5.80738985e-01,  1.83736989e+00,  1.61677383e+00, -2.57129421e+00,\n",
       "       -8.53144715e-01, -1.51784806e+00, -2.75566371e+00, -2.80859095e+00,\n",
       "        6.71065919e-01, -3.77732535e+00, -2.55664027e+00,  7.48663357e-01,\n",
       "       -3.34666807e+00, -3.49897611e+00,  5.07694257e-03, -2.59416853e+00,\n",
       "       -3.11445183e+00, -3.68423354e+00, -3.38554395e-02, -3.55485717e+00,\n",
       "        2.32073120e+00, -3.61008650e+00,  2.27063282e-01, -1.30104147e+00,\n",
       "        2.30379206e+00, -2.55858082e+00, -3.17834629e+00, -2.07791251e+00,\n",
       "       -3.73846813e+00, -2.10611428e+00, -9.74822860e-01,  3.60393907e+00,\n",
       "       -2.40003643e+00, -1.57983908e+00, -3.03973461e+00, -2.86266536e+00,\n",
       "       -2.87330636e+00, -2.29598657e-01, -1.25090195e+00, -6.43047434e-01,\n",
       "        1.69571541e+00, -4.42991417e+00,  1.99424633e+00, -2.53291724e+00,\n",
       "        3.26072147e-01,  7.33103978e-01, -3.93903279e+00, -3.20981343e+00,\n",
       "       -2.41324602e+00, -1.85037610e+00, -2.43742077e+00,  5.78124150e-01,\n",
       "       -2.39485817e+00, -2.46030742e+00, -2.62506527e-01,  1.85633902e+00,\n",
       "       -2.21410302e+00, -2.23034966e+00, -1.64145831e+00, -2.24804096e+00,\n",
       "       -2.75615881e+00, -1.60923836e+00, -3.66155071e+00, -3.50696049e+00,\n",
       "       -3.57590695e+00, -3.13622878e+00, -3.23573023e-01, -3.18937136e+00,\n",
       "       -1.48400786e+00,  1.55029128e-01, -2.84113139e+00, -1.61857407e+00,\n",
       "        2.00722201e+00,  9.52540874e-01, -3.80847945e+00,  1.78588015e+00,\n",
       "       -1.78360824e+00, -4.85147648e+00,  1.48208920e+00, -2.72811082e+00,\n",
       "       -3.46109729e+00, -2.60305484e+00, -3.73005471e+00, -2.33391465e+00,\n",
       "       -4.47166365e+00, -3.93004902e+00, -1.80141536e+00,  1.55735328e+00,\n",
       "        5.52213938e-01, -3.24418560e+00, -2.79007976e+00,  1.71484509e+00,\n",
       "        3.97563099e-01, -4.24080636e+00, -2.70239769e+00,  1.63324256e+00,\n",
       "       -2.58710707e+00,  4.36701710e-01,  1.00030520e+00,  1.62088271e+00,\n",
       "       -3.34960899e+00, -1.94567001e+00,  1.94722472e+00,  1.80169000e+00,\n",
       "       -7.78392862e-01,  1.54481184e+00, -4.18739291e+00, -2.56810656e+00,\n",
       "        2.11916172e+00, -3.39442714e+00, -1.84444230e+00, -3.11675426e+00,\n",
       "        1.33148683e+00, -2.05703271e+00, -2.03936800e+00, -2.38924052e+00,\n",
       "       -1.51928931e+00, -3.03919151e+00,  5.46293789e-01,  1.17774319e+00,\n",
       "       -1.70292181e+00, -2.54619023e+00, -3.27990554e+00,  7.72444770e-01,\n",
       "       -3.34478256e+00, -3.41818909e+00, -2.55727422e+00, -5.80732778e-01,\n",
       "        1.83098165e+00, -1.17012761e+00, -2.05370229e+00,  1.41979750e+00,\n",
       "       -1.23357219e+00, -3.30010158e+00, -3.11920748e+00, -3.25711045e+00,\n",
       "       -3.47111409e+00, -2.30200904e+00, -1.27003764e+00, -1.47820609e+00,\n",
       "       -1.28596389e+00, -3.93492645e+00,  2.48552680e+00,  1.21527179e+00,\n",
       "       -2.70120265e+00, -7.67493667e-01, -1.95268898e+00, -2.42135520e+00,\n",
       "       -2.49837671e+00, -3.09792501e+00, -1.36311832e+00, -1.77131631e+00,\n",
       "        1.34871707e+00,  4.29122191e-01, -2.17661262e+00, -1.08786850e+00,\n",
       "       -2.51167347e+00,  7.69278223e-01,  5.37756695e-01, -3.35110542e+00,\n",
       "       -2.44357113e+00,  1.87709963e+00,  1.52763485e+00, -1.47010927e+00,\n",
       "       -1.32251808e+00, -3.15845436e+00, -3.19082292e-01, -1.79490271e+00,\n",
       "       -2.53840597e+00, -3.40729237e+00,  2.52590300e+00, -3.41761400e+00,\n",
       "        1.00996253e-01, -3.27559605e+00,  3.75184882e-01,  1.63399569e+00,\n",
       "       -1.06598436e+00, -2.87348900e+00, -1.17935836e+00,  2.52144430e+00,\n",
       "        1.42766171e+00, -3.38190215e+00, -1.56233136e+00, -1.64817463e+00,\n",
       "        4.60146340e-01, -1.76088189e+00, -1.76965953e+00,  1.63284269e+00,\n",
       "       -4.31427804e+00, -2.97246169e+00,  1.46094889e-01,  1.73191495e+00,\n",
       "       -1.01065505e+00,  1.52972598e+00,  1.79611499e+00, -7.11655932e-01,\n",
       "        1.60597576e+00,  1.32023617e+00, -2.77870214e+00, -3.06035420e+00,\n",
       "        5.04808865e-01,  1.57080973e+00, -1.55251992e+00,  1.43191763e+00,\n",
       "        1.56263706e-01,  2.22941011e+00,  6.73495262e-01, -2.56850749e+00,\n",
       "       -3.80030153e+00, -3.24641603e+00, -1.86371785e+00, -2.26976563e+00,\n",
       "       -1.87930045e+00, -3.67352301e+00, -2.12186449e+00, -1.93887701e+00,\n",
       "       -3.65012727e+00,  2.13573046e+00, -2.95548705e+00,  7.01497390e-01,\n",
       "        1.42329407e+00, -3.50392442e+00, -3.18582092e+00, -2.91256363e+00,\n",
       "       -2.02415664e+00,  1.83384559e+00, -3.88945554e+00,  1.26111313e+00,\n",
       "        2.83832383e+00,  1.60858565e+00, -6.51092329e-01, -3.01044159e+00,\n",
       "       -4.40833577e+00, -3.14141408e+00, -2.01663033e+00, -1.01072742e+00,\n",
       "       -2.96616275e+00,  4.85285890e-01, -2.00673323e+00, -1.67940982e+00,\n",
       "        1.85134310e+00, -2.62868404e+00, -4.77223433e-01, -1.56330408e+00,\n",
       "       -3.22870008e+00,  9.92340065e-01, -1.63509579e+00, -9.00812892e-01,\n",
       "        6.00698907e-01, -2.75885741e+00, -2.58041763e+00, -4.88550147e-01,\n",
       "       -2.93638052e+00,  1.28568025e+00,  1.39285016e+00, -3.48974322e+00,\n",
       "       -1.70687206e+00,  8.12244074e-01, -2.82839423e+00, -3.01602810e+00,\n",
       "       -1.68724833e+00, -4.51056207e-01,  6.09678284e-01, -2.63431664e+00,\n",
       "        1.38063279e+00,  1.38019604e+00, -5.55400699e-01,  5.27718641e-01,\n",
       "       -2.26080612e+00, -3.32691781e+00, -8.53610643e-02,  2.30635883e+00,\n",
       "       -2.40193859e+00, -1.45694855e+00, -2.83563604e+00, -4.03647389e+00,\n",
       "       -1.42472925e+00, -3.23068241e+00, -3.18033419e+00,  7.60882123e-01,\n",
       "        1.83695057e+00, -2.89820581e+00,  1.31777826e+00,  1.80104693e+00,\n",
       "       -1.21502769e+00, -2.52702391e+00, -1.76519545e+00, -2.65466657e+00,\n",
       "        1.42376124e+00, -1.56598923e+00,  5.66184708e-01,  1.60020777e+00,\n",
       "       -2.14518557e+00, -3.25064632e+00, -2.80525757e+00, -2.37811908e+00,\n",
       "        1.90660036e+00, -2.64703532e+00, -2.42643819e+00, -3.71965918e+00,\n",
       "        3.60674587e-01, -3.51359822e+00, -9.27385279e-02, -2.21373524e+00,\n",
       "       -1.98459661e-01, -3.07290797e+00, -2.61117046e+00, -3.18517435e+00,\n",
       "        8.44101866e-01, -2.73160364e+00, -3.01524483e+00, -3.86771079e+00,\n",
       "        2.54749712e+00, -2.19266382e+00, -2.29850565e+00, -2.74356691e+00,\n",
       "       -2.28780380e+00, -1.55504900e+00,  2.09463158e+00, -1.46671120e+00,\n",
       "        1.85606896e+00, -2.57366899e+00, -3.29088226e+00, -1.44132804e+00,\n",
       "       -2.51771386e+00,  1.86681536e+00, -3.44842539e+00, -2.11691766e+00,\n",
       "        1.29766539e+00, -9.33224366e-01,  1.57530281e+00, -1.29210602e+00,\n",
       "       -2.49700531e+00, -3.22358045e+00, -2.15301951e+00,  1.20870006e+00,\n",
       "        2.23276695e+00,  1.71995963e+00, -2.79981115e+00, -3.13631304e+00,\n",
       "        3.44020457e-01, -5.08041882e-01,  8.65779936e-01,  1.69240989e-01,\n",
       "        1.65172317e+00, -2.21374396e+00, -1.26885524e+00, -1.92142197e+00,\n",
       "        7.82262614e-02, -2.53243322e+00, -2.34112040e+00,  1.65666476e+00,\n",
       "        4.13586691e-01, -3.12815749e+00, -3.14327001e+00, -3.58284661e+00,\n",
       "        5.20290158e-01, -1.77168350e+00, -1.76189538e+00, -1.99032886e+00,\n",
       "       -3.12396422e+00, -2.85766618e+00, -9.16820042e-01,  1.79531935e+00,\n",
       "       -1.66974762e+00, -2.81742243e+00, -1.60444777e+00, -1.68425308e+00,\n",
       "        2.04312837e+00,  1.61928208e+00, -2.82126245e+00, -1.71321615e+00,\n",
       "        1.92611958e+00,  2.27004839e+00,  1.00368368e+00, -4.61254335e+00,\n",
       "       -2.34633890e+00, -2.28403163e+00, -1.33125556e+00, -2.11516270e+00,\n",
       "        5.62985613e-01, -2.46512165e+00,  1.77881551e+00, -1.95976855e+00,\n",
       "       -2.52838605e+00,  1.65014736e+00,  1.94409341e+00,  3.29145636e-01,\n",
       "       -1.32628895e+00, -2.99092018e+00, -2.97495262e+00, -3.12355025e-01,\n",
       "       -3.46939085e-01, -4.10235819e+00, -1.60723880e+00, -3.16529859e+00,\n",
       "        8.18095230e-01, -1.54544920e+00, -1.88690103e+00, -3.12751636e+00,\n",
       "        1.61344833e+00, -4.10786252e+00, -9.94703812e-01,  2.02489312e+00,\n",
       "       -8.22289467e-01, -3.22678724e+00, -3.13881860e+00,  1.02447437e+00,\n",
       "       -2.47027517e+00,  1.64064828e+00, -1.22235610e+00, -2.47767360e+00,\n",
       "       -1.10677614e+00,  9.29994245e-01, -1.98450507e+00,  1.28073177e+00,\n",
       "       -7.53887154e-01,  1.27964806e+00, -2.79568194e+00, -6.09805524e-01,\n",
       "       -3.89065828e+00, -3.65428560e+00,  4.14834389e+00, -2.52406305e+00,\n",
       "        3.42938455e+00, -2.98461266e+00, -3.96022663e+00, -2.68986643e+00,\n",
       "        1.73984637e-01, -9.46959127e-01,  1.96178250e+00, -3.03865663e+00,\n",
       "       -5.75292326e-01,  2.11134212e+00, -2.13621330e+00, -2.44208773e+00,\n",
       "        1.74720352e+00, -1.93648131e+00,  1.52416033e+00, -1.33058985e+00,\n",
       "        1.37396141e+00, -3.59416463e+00, -1.92235269e+00,  1.95260268e+00,\n",
       "       -2.88792766e+00,  6.52197964e-01, -1.91781056e+00, -4.25270852e+00,\n",
       "       -3.38824570e+00, -1.20791195e+00, -1.04141802e+00,  1.79764211e+00,\n",
       "       -3.03630227e+00, -2.65547571e+00,  1.82074681e+00, -1.66998654e+00,\n",
       "       -3.82180200e+00,  1.69031926e-01, -2.17912166e+00, -1.81418124e+00,\n",
       "       -1.04873968e+00,  1.78357669e+00, -8.45332763e-01,  2.27005657e+00,\n",
       "       -7.69189766e-01, -1.81972634e+00, -2.09342807e+00, -2.24578843e+00,\n",
       "        2.08681883e-01, -2.42074131e+00, -1.07781839e+00, -3.02122600e+00,\n",
       "        1.73345724e+00, -1.45720376e+00,  1.34769878e+00, -3.26496977e+00,\n",
       "       -2.69471799e+00, -2.32534477e+00, -2.31030478e+00, -1.97460011e+00,\n",
       "       -3.51215610e+00, -2.84475785e+00, -2.24067026e+00,  1.00112009e+00,\n",
       "       -2.82859354e+00, -1.90315648e+00,  2.06347876e+00, -2.46808796e+00,\n",
       "       -3.05798434e+00, -6.90274839e-01, -1.73777738e+00,  1.25327801e+00,\n",
       "        6.59874115e-02, -2.08073385e+00, -1.73022971e+00,  2.88157014e+00,\n",
       "        3.19657240e+00, -2.88816783e+00,  1.76009338e+00,  1.97633682e+00])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.decision_function(x_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tHie1zqH4Zxt"
   },
   "source": [
    "### Pseudo code\n",
    "\n",
    "clf = SVC(gamma=0.001, C=100.)<br>\n",
    "clf.fit(Xtrain, ytrain)\n",
    "\n",
    "<font color='green'>def</font> <font color='blue'>decision_function</font>(Xcv, ...): #use appropriate parameters <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color='green'>for</font> a data point $x_q$ <font color='green'>in</font> Xcv: <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color='grey'>#write code to implement $(\\sum_{i=1}^{\\text{all the support vectors}}(y_{i}\\alpha_{i}K(x_{i},x_{q})) + intercept)$, here the values $y_i$, $\\alpha_{i}$, and $intercept$ can be obtained from the trained model</font><br>\n",
    "   <font color='green'>return</font> <font color='grey'><i># the decision_function output for all the data points in the Xcv</i></font>\n",
    "    \n",
    "fcv = decision_function(Xcv, ...)  <i># based on your requirement you can pass any other parameters </i>\n",
    "\n",
    "<b>Note</b>: Make sure the values you get as fcv, should be equal to outputs of clf.decision_function(Xcv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_function(x_cv):\n",
    "    alphas = clf.dual_coef_[0]\n",
    "    decision_function = []\n",
    "    for Xq in x_cv:\n",
    "        sum = clf.intercept_[0]\n",
    "        for i,supvec in enumerate(clf.support_vectors_):\n",
    "            norm = np.linalg.norm(supvec - Xq)**2\n",
    "            kernel = np.exp(-0.001*norm)\n",
    "            #print(kernel)\n",
    "            sum += (alphas[i]*kernel)\n",
    "        #print(sum)\n",
    "        decision_function.append(sum)\n",
    "        \n",
    "    return np.array(decision_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.57463800e+00, -1.82232960e+00, -2.65223514e+00, -2.62951012e+00,\n",
       "       -3.55136263e+00,  1.53082124e+00, -1.93158819e+00,  1.71616352e+00,\n",
       "       -3.24615433e+00,  1.75518204e+00, -1.92898337e+00,  9.29804561e-01,\n",
       "       -2.28326203e+00, -3.47104530e+00, -4.32849183e+00, -2.36488835e+00,\n",
       "        1.75084839e+00,  2.27457941e+00,  1.85652750e+00,  1.90366607e+00,\n",
       "       -1.14806849e-01, -3.27193926e+00, -2.30867747e+00, -3.02098803e+00,\n",
       "       -1.96542611e+00, -4.19181958e+00,  1.32367762e+00, -2.93461272e+00,\n",
       "        2.29102600e-01, -3.04023069e+00,  1.07897533e+00, -2.96276200e+00,\n",
       "       -2.92328222e+00, -1.99178121e+00, -2.32860913e-01,  3.85018521e-01,\n",
       "       -1.70072224e+00,  1.66726145e+00, -3.41951275e+00,  1.61539505e+00,\n",
       "       -3.44192309e+00,  2.23479270e+00, -1.74239380e+00,  1.14387877e+00,\n",
       "       -2.68917459e+00,  1.25972795e+00, -1.70527396e+00, -3.14112465e+00,\n",
       "        1.62461022e+00,  1.69315782e+00,  1.06685386e+00, -2.99349347e+00,\n",
       "       -1.94300419e+00,  2.04753172e+00, -2.38344528e+00, -2.19628646e+00,\n",
       "       -3.62315610e-01, -1.30200371e+00, -2.88006032e+00, -8.19825384e-01,\n",
       "        2.41659402e+00, -1.60915516e+00, -3.98486518e+00, -2.24717402e+00,\n",
       "        1.82436443e+00,  3.41859992e+00,  1.40179639e+00, -2.56640761e+00,\n",
       "       -2.51409819e+00,  5.11747982e-01, -3.44712087e+00, -1.83135321e+00,\n",
       "        1.55546432e+00, -3.15146914e+00, -2.48317493e+00, -4.24635268e+00,\n",
       "       -1.01659159e-01, -2.81344171e+00, -3.51658262e+00, -3.24556274e+00,\n",
       "        1.28601107e+00,  2.14046365e-01, -6.03294450e-01, -2.27941583e+00,\n",
       "       -7.47798331e-01,  1.02606120e+00, -2.37400989e+00, -3.50109581e+00,\n",
       "       -3.42829286e+00,  7.99885388e-01, -1.85608799e+00, -4.09306379e+00,\n",
       "       -1.79363601e+00, -3.32393350e+00, -3.63649014e+00, -4.75842386e-01,\n",
       "       -7.91513890e-01, -2.53224616e+00, -3.09277750e+00, -2.65953187e+00,\n",
       "        7.31179403e-01, -2.09051845e+00,  1.22043784e+00, -2.85193302e+00,\n",
       "        9.03891641e-01, -1.90030107e+00, -1.33387197e+00, -3.60209572e+00,\n",
       "        2.10089860e+00,  1.79431205e+00, -3.16663505e+00,  2.70856301e+00,\n",
       "       -3.68721045e+00,  3.90990534e-01, -8.19796607e-01, -2.97995859e+00,\n",
       "       -2.94920970e+00, -2.72265064e+00, -3.22389422e+00, -2.94791837e+00,\n",
       "       -4.41889769e+00, -3.07514172e+00, -2.59641406e+00, -1.76239503e+00,\n",
       "       -2.28399706e+00, -4.40884095e+00, -2.03646624e+00,  2.62482995e+00,\n",
       "        1.42545770e+00, -1.08786198e+00,  3.78690126e-01, -3.45406325e+00,\n",
       "       -4.00887675e+00, -2.95456439e+00,  2.00149119e+00,  1.69759315e+00,\n",
       "       -3.42912928e+00, -1.75287506e+00, -2.84780948e+00, -2.90552886e+00,\n",
       "       -2.22455482e+00,  1.76882484e+00,  1.90448851e+00, -2.30863309e+00,\n",
       "       -4.04784083e+00,  2.03687926e+00, -2.75439094e+00, -2.10838803e+00,\n",
       "       -5.10247631e-02, -5.15373338e-01,  1.88821213e+00,  1.74275025e+00,\n",
       "       -2.55380037e+00, -2.45230240e+00, -2.04085967e+00, -2.75952470e+00,\n",
       "       -1.85610886e+00, -8.00880086e-02,  1.74606877e+00,  1.81579474e+00,\n",
       "       -2.25554961e+00,  1.22436283e-01, -1.08543106e+00, -2.56983227e+00,\n",
       "       -3.05321412e+00,  1.80472237e+00, -3.16244134e+00,  2.05565305e+00,\n",
       "       -2.23534434e+00, -1.55334065e+00, -6.64626314e+00, -2.59280374e+00,\n",
       "       -2.27009469e-01, -1.13575946e-01, -3.28919583e+00, -1.69253234e+00,\n",
       "       -2.02261735e+00, -3.88367192e-01, -4.54555393e+00, -2.82768208e+00,\n",
       "        1.17928591e+00,  8.07102014e-01, -1.86037838e+00,  9.28905167e-01,\n",
       "        6.13032839e-01,  2.09573602e+00,  9.71148397e-01, -3.65933467e+00,\n",
       "       -8.30721384e-01,  1.35782561e+00,  7.89890636e-01, -2.27116233e+00,\n",
       "       -3.17208094e+00,  1.81577884e+00, -2.12701345e+00, -2.37757661e+00,\n",
       "        1.83791520e+00, -3.23501914e+00, -8.81159001e-01, -4.07242756e+00,\n",
       "        1.95735701e+00, -2.66753566e-01, -1.66385236e+00,  1.72416976e+00,\n",
       "       -3.72910233e+00,  2.59509398e-01,  3.48013672e+00, -1.44588039e+00,\n",
       "        2.05286427e+00, -4.17978783e+00,  8.77213088e-01, -2.52569130e+00,\n",
       "       -6.08074556e-01, -3.60678900e+00, -3.19911903e+00,  1.46604166e+00,\n",
       "       -2.43148760e-01,  3.27842807e-02, -2.03731856e+00,  2.69817452e-01,\n",
       "       -1.69293651e+00,  2.21902605e+00, -2.94305662e+00, -6.81857833e-01,\n",
       "       -2.11199566e+00, -1.74163319e+00,  6.36757971e-01, -2.04722945e+00,\n",
       "        1.69271746e+00, -2.94690610e+00, -1.42138312e+00, -3.22087482e+00,\n",
       "        2.89310379e+00, -3.06763830e+00, -4.13245075e+00,  1.08851913e+00,\n",
       "       -2.52281648e+00,  2.15932000e+00, -2.28362762e+00,  5.13892690e-01,\n",
       "       -2.05339050e+00, -2.83518355e+00, -2.27123281e+00,  2.10404959e+00,\n",
       "       -2.14463777e+00, -1.69666676e+00, -1.09800140e+00,  9.97310834e-01,\n",
       "        1.25583180e+00, -1.67705556e+00,  1.03167167e+00, -1.62867410e+00,\n",
       "        5.40194331e-01, -1.49769687e+00, -2.71233535e-01,  1.51151929e+00,\n",
       "       -2.66794109e+00,  2.11759729e+00, -3.92819017e+00, -7.76735398e-01,\n",
       "        1.22619437e+00, -2.98539660e+00, -1.33361845e+00, -3.16679864e+00,\n",
       "        7.44316449e-01,  1.69663073e+00,  1.46947627e+00, -1.82129809e+00,\n",
       "        1.83274461e+00,  1.99620609e+00, -2.64979811e+00, -2.16414026e-01,\n",
       "       -3.29635822e+00, -2.44556914e+00, -1.92851139e+00,  1.74163285e+00,\n",
       "       -3.18529111e+00, -2.75812644e+00, -2.70669195e+00, -6.88179854e+00,\n",
       "        1.10392893e+00, -3.01508227e+00, -2.46039354e+00, -2.89777097e+00,\n",
       "       -3.05515787e+00, -3.44249257e+00, -1.32652358e+00,  1.25038143e+00,\n",
       "        1.69035897e+00,  1.99892119e-02, -2.20611084e+00, -3.32332510e+00,\n",
       "        1.13503126e+00,  1.28561437e+00,  1.45846868e+00, -3.17355173e+00,\n",
       "        1.66189619e+00,  1.69418020e+00, -2.22745829e+00, -4.02890078e+00,\n",
       "       -2.25933302e+00, -2.46709359e+00, -2.53303246e+00, -2.72257530e+00,\n",
       "       -3.72841323e+00, -4.08904008e+00,  7.14917958e-01,  9.01089391e-01,\n",
       "       -1.70610495e+00,  1.18306580e+00, -4.05270385e+00,  2.92211120e-01,\n",
       "        6.21924085e-01,  7.44335710e-01, -2.59168625e+00, -2.34809103e+00,\n",
       "       -1.85146009e+00, -1.15698448e+00, -2.42589857e+00, -1.58458148e+00,\n",
       "       -4.48662763e+00, -1.96174695e+00, -1.13719016e+00, -7.23011894e-01,\n",
       "        2.05671325e+00, -2.49436943e+00, -2.97944860e+00, -2.71353137e+00,\n",
       "       -2.43711635e+00, -1.59478903e+00, -4.06089083e-01, -2.11083389e+00,\n",
       "        1.26096053e+00, -1.53165470e+00,  1.03168798e+00,  1.86261827e+00,\n",
       "       -2.21761542e+00, -8.14069860e-01,  1.96784306e-01, -2.17324090e+00,\n",
       "       -3.04507168e+00, -1.75425007e+00, -4.00350544e+00, -2.00137029e+00,\n",
       "       -4.14233974e-01, -3.32281021e+00,  1.93597480e+00,  1.45901880e+00,\n",
       "       -2.06950665e+00, -3.02890101e+00,  1.64799786e+00,  1.57373048e+00,\n",
       "       -1.75393383e+00, -1.85179572e+00, -3.11458121e+00, -4.28231865e+00,\n",
       "       -3.91718151e+00, -2.48290596e+00, -1.65378020e+00, -2.43633141e+00,\n",
       "        1.35334067e+00, -2.07676071e+00, -2.68969393e+00,  1.50339385e+00,\n",
       "       -4.01580168e+00, -5.77485919e-02,  2.34961199e+00, -1.12334868e+00,\n",
       "       -1.90822495e+00,  1.34598083e+00, -3.27868493e+00, -2.43549393e+00,\n",
       "        1.92253021e+00, -2.05487975e+00, -3.04787623e-01,  4.12545539e-01,\n",
       "       -3.34237275e+00, -3.10222040e+00, -2.09837629e+00,  1.78915431e+00,\n",
       "       -2.53700802e+00, -3.74106095e-01,  3.58138538e-01,  4.07599941e-01,\n",
       "        3.68049798e-01, -1.65280340e+00,  1.03009176e+00, -1.38545684e+00,\n",
       "       -3.86824656e+00, -1.67954384e+00, -2.02786800e+00, -1.12455725e+00,\n",
       "       -3.00575222e+00,  2.68180538e+00, -2.20274814e+00, -2.73343659e+00,\n",
       "       -4.80492025e+00, -3.59901791e+00, -2.12743572e+00, -3.77597507e+00,\n",
       "        1.54960750e+00, -2.57488528e+00, -2.50619700e+00, -2.04777416e+00,\n",
       "       -2.99710690e-01,  1.26236667e+00, -2.18261457e+00,  1.61586006e+00,\n",
       "       -2.93960302e+00, -1.92143714e+00, -2.73324327e-01, -2.92405282e+00,\n",
       "        2.24924018e+00,  2.95459600e+00, -2.73714282e+00, -8.17691232e-01,\n",
       "       -2.38794790e+00,  1.64434625e+00,  2.42311343e-01,  1.37075558e+00,\n",
       "       -1.73243516e+00,  1.56167475e+00, -3.01500618e+00, -3.15785772e+00,\n",
       "       -5.33298300e-01,  1.26229260e+00,  1.64477177e+00,  2.01583957e-01,\n",
       "       -4.17859942e+00, -4.72876313e+00,  1.45673599e+00,  5.94202220e-02,\n",
       "        4.82929546e-01, -1.55434041e+00, -5.88321377e-01, -1.83860225e+00,\n",
       "        1.41694976e+00,  2.33112492e-01, -2.75499747e-01, -2.58333547e+00,\n",
       "       -3.54736791e+00, -8.42244026e-01, -3.38431201e+00, -3.33208894e+00,\n",
       "       -3.79832272e+00, -4.99313241e-01,  1.56257079e+00, -2.46002411e+00,\n",
       "        1.68505786e+00, -1.55595751e+00, -5.58598277e-01,  1.93694749e+00,\n",
       "        7.09320710e-01, -2.95240063e+00, -7.60345979e-01,  1.67705865e+00,\n",
       "       -1.99754852e+00, -3.62103941e+00, -5.46812645e-03, -8.85535970e-01,\n",
       "        7.60474310e-01, -2.41986570e+00,  2.36260990e+00,  2.00550158e+00,\n",
       "        1.66358439e+00, -1.93649932e+00, -2.29995511e+00,  1.17591486e+00,\n",
       "        9.52003533e-02, -1.80591786e+00, -3.15320026e+00, -2.24814852e+00,\n",
       "       -7.76256256e-02, -3.05377786e+00, -1.86688771e+00, -1.67436996e+00,\n",
       "       -2.43291890e+00, -9.67773166e-01, -1.42487539e+00, -2.92329355e+00,\n",
       "       -3.58736927e+00, -1.16564341e+00, -3.05926713e+00, -2.83295810e+00,\n",
       "       -2.64769458e+00, -3.07857572e+00, -2.53814048e+00,  5.98228072e-01,\n",
       "       -2.87539471e+00,  9.98310491e-01, -2.78715026e+00, -1.05197072e+00,\n",
       "       -1.39959853e+00, -1.93092720e+00, -3.89221464e+00, -2.34055304e+00,\n",
       "       -4.12440823e+00,  1.01716641e+00, -2.56998652e+00, -2.01389211e+00,\n",
       "       -5.80738985e-01,  1.83736989e+00,  1.61677383e+00, -2.57129421e+00,\n",
       "       -8.53144715e-01, -1.51784806e+00, -2.75566371e+00, -2.80859095e+00,\n",
       "        6.71065919e-01, -3.77732535e+00, -2.55664027e+00,  7.48663357e-01,\n",
       "       -3.34666807e+00, -3.49897611e+00,  5.07694257e-03, -2.59416853e+00,\n",
       "       -3.11445183e+00, -3.68423354e+00, -3.38554395e-02, -3.55485717e+00,\n",
       "        2.32073120e+00, -3.61008650e+00,  2.27063282e-01, -1.30104147e+00,\n",
       "        2.30379206e+00, -2.55858082e+00, -3.17834629e+00, -2.07791251e+00,\n",
       "       -3.73846813e+00, -2.10611428e+00, -9.74822860e-01,  3.60393907e+00,\n",
       "       -2.40003643e+00, -1.57983908e+00, -3.03973461e+00, -2.86266536e+00,\n",
       "       -2.87330636e+00, -2.29598657e-01, -1.25090195e+00, -6.43047434e-01,\n",
       "        1.69571541e+00, -4.42991417e+00,  1.99424633e+00, -2.53291724e+00,\n",
       "        3.26072147e-01,  7.33103978e-01, -3.93903279e+00, -3.20981343e+00,\n",
       "       -2.41324602e+00, -1.85037610e+00, -2.43742077e+00,  5.78124150e-01,\n",
       "       -2.39485817e+00, -2.46030742e+00, -2.62506527e-01,  1.85633902e+00,\n",
       "       -2.21410302e+00, -2.23034966e+00, -1.64145831e+00, -2.24804096e+00,\n",
       "       -2.75615881e+00, -1.60923836e+00, -3.66155071e+00, -3.50696049e+00,\n",
       "       -3.57590695e+00, -3.13622878e+00, -3.23573023e-01, -3.18937136e+00,\n",
       "       -1.48400786e+00,  1.55029128e-01, -2.84113139e+00, -1.61857407e+00,\n",
       "        2.00722201e+00,  9.52540874e-01, -3.80847945e+00,  1.78588015e+00,\n",
       "       -1.78360824e+00, -4.85147648e+00,  1.48208920e+00, -2.72811082e+00,\n",
       "       -3.46109729e+00, -2.60305484e+00, -3.73005471e+00, -2.33391465e+00,\n",
       "       -4.47166365e+00, -3.93004902e+00, -1.80141536e+00,  1.55735328e+00,\n",
       "        5.52213938e-01, -3.24418560e+00, -2.79007976e+00,  1.71484509e+00,\n",
       "        3.97563099e-01, -4.24080636e+00, -2.70239769e+00,  1.63324256e+00,\n",
       "       -2.58710707e+00,  4.36701710e-01,  1.00030520e+00,  1.62088271e+00,\n",
       "       -3.34960899e+00, -1.94567001e+00,  1.94722472e+00,  1.80169000e+00,\n",
       "       -7.78392862e-01,  1.54481184e+00, -4.18739291e+00, -2.56810656e+00,\n",
       "        2.11916172e+00, -3.39442714e+00, -1.84444230e+00, -3.11675426e+00,\n",
       "        1.33148683e+00, -2.05703271e+00, -2.03936800e+00, -2.38924052e+00,\n",
       "       -1.51928931e+00, -3.03919151e+00,  5.46293789e-01,  1.17774319e+00,\n",
       "       -1.70292181e+00, -2.54619023e+00, -3.27990554e+00,  7.72444770e-01,\n",
       "       -3.34478256e+00, -3.41818909e+00, -2.55727422e+00, -5.80732778e-01,\n",
       "        1.83098165e+00, -1.17012761e+00, -2.05370229e+00,  1.41979750e+00,\n",
       "       -1.23357219e+00, -3.30010158e+00, -3.11920748e+00, -3.25711045e+00,\n",
       "       -3.47111409e+00, -2.30200904e+00, -1.27003764e+00, -1.47820609e+00,\n",
       "       -1.28596389e+00, -3.93492645e+00,  2.48552680e+00,  1.21527179e+00,\n",
       "       -2.70120265e+00, -7.67493667e-01, -1.95268898e+00, -2.42135520e+00,\n",
       "       -2.49837671e+00, -3.09792501e+00, -1.36311832e+00, -1.77131631e+00,\n",
       "        1.34871707e+00,  4.29122191e-01, -2.17661262e+00, -1.08786850e+00,\n",
       "       -2.51167347e+00,  7.69278223e-01,  5.37756695e-01, -3.35110542e+00,\n",
       "       -2.44357113e+00,  1.87709963e+00,  1.52763485e+00, -1.47010927e+00,\n",
       "       -1.32251808e+00, -3.15845436e+00, -3.19082292e-01, -1.79490271e+00,\n",
       "       -2.53840597e+00, -3.40729237e+00,  2.52590300e+00, -3.41761400e+00,\n",
       "        1.00996253e-01, -3.27559605e+00,  3.75184882e-01,  1.63399569e+00,\n",
       "       -1.06598436e+00, -2.87348900e+00, -1.17935836e+00,  2.52144430e+00,\n",
       "        1.42766171e+00, -3.38190215e+00, -1.56233136e+00, -1.64817463e+00,\n",
       "        4.60146340e-01, -1.76088189e+00, -1.76965953e+00,  1.63284269e+00,\n",
       "       -4.31427804e+00, -2.97246169e+00,  1.46094889e-01,  1.73191495e+00,\n",
       "       -1.01065505e+00,  1.52972598e+00,  1.79611499e+00, -7.11655932e-01,\n",
       "        1.60597576e+00,  1.32023617e+00, -2.77870214e+00, -3.06035420e+00,\n",
       "        5.04808865e-01,  1.57080973e+00, -1.55251992e+00,  1.43191763e+00,\n",
       "        1.56263706e-01,  2.22941011e+00,  6.73495262e-01, -2.56850749e+00,\n",
       "       -3.80030153e+00, -3.24641603e+00, -1.86371785e+00, -2.26976563e+00,\n",
       "       -1.87930045e+00, -3.67352301e+00, -2.12186449e+00, -1.93887701e+00,\n",
       "       -3.65012727e+00,  2.13573046e+00, -2.95548705e+00,  7.01497390e-01,\n",
       "        1.42329407e+00, -3.50392442e+00, -3.18582092e+00, -2.91256363e+00,\n",
       "       -2.02415664e+00,  1.83384559e+00, -3.88945554e+00,  1.26111313e+00,\n",
       "        2.83832383e+00,  1.60858565e+00, -6.51092329e-01, -3.01044159e+00,\n",
       "       -4.40833577e+00, -3.14141408e+00, -2.01663033e+00, -1.01072742e+00,\n",
       "       -2.96616275e+00,  4.85285890e-01, -2.00673323e+00, -1.67940982e+00,\n",
       "        1.85134310e+00, -2.62868404e+00, -4.77223433e-01, -1.56330408e+00,\n",
       "       -3.22870008e+00,  9.92340065e-01, -1.63509579e+00, -9.00812892e-01,\n",
       "        6.00698907e-01, -2.75885741e+00, -2.58041763e+00, -4.88550147e-01,\n",
       "       -2.93638052e+00,  1.28568025e+00,  1.39285016e+00, -3.48974322e+00,\n",
       "       -1.70687206e+00,  8.12244074e-01, -2.82839423e+00, -3.01602810e+00,\n",
       "       -1.68724833e+00, -4.51056207e-01,  6.09678284e-01, -2.63431664e+00,\n",
       "        1.38063279e+00,  1.38019604e+00, -5.55400699e-01,  5.27718641e-01,\n",
       "       -2.26080612e+00, -3.32691781e+00, -8.53610643e-02,  2.30635883e+00,\n",
       "       -2.40193859e+00, -1.45694855e+00, -2.83563604e+00, -4.03647389e+00,\n",
       "       -1.42472925e+00, -3.23068241e+00, -3.18033419e+00,  7.60882123e-01,\n",
       "        1.83695057e+00, -2.89820581e+00,  1.31777826e+00,  1.80104693e+00,\n",
       "       -1.21502769e+00, -2.52702391e+00, -1.76519545e+00, -2.65466657e+00,\n",
       "        1.42376124e+00, -1.56598923e+00,  5.66184708e-01,  1.60020777e+00,\n",
       "       -2.14518557e+00, -3.25064632e+00, -2.80525757e+00, -2.37811908e+00,\n",
       "        1.90660036e+00, -2.64703532e+00, -2.42643819e+00, -3.71965918e+00,\n",
       "        3.60674587e-01, -3.51359822e+00, -9.27385279e-02, -2.21373524e+00,\n",
       "       -1.98459661e-01, -3.07290797e+00, -2.61117046e+00, -3.18517435e+00,\n",
       "        8.44101866e-01, -2.73160364e+00, -3.01524483e+00, -3.86771079e+00,\n",
       "        2.54749712e+00, -2.19266382e+00, -2.29850565e+00, -2.74356691e+00,\n",
       "       -2.28780380e+00, -1.55504900e+00,  2.09463158e+00, -1.46671120e+00,\n",
       "        1.85606896e+00, -2.57366899e+00, -3.29088226e+00, -1.44132804e+00,\n",
       "       -2.51771386e+00,  1.86681536e+00, -3.44842539e+00, -2.11691766e+00,\n",
       "        1.29766539e+00, -9.33224366e-01,  1.57530281e+00, -1.29210602e+00,\n",
       "       -2.49700531e+00, -3.22358045e+00, -2.15301951e+00,  1.20870006e+00,\n",
       "        2.23276695e+00,  1.71995963e+00, -2.79981115e+00, -3.13631304e+00,\n",
       "        3.44020457e-01, -5.08041882e-01,  8.65779936e-01,  1.69240989e-01,\n",
       "        1.65172317e+00, -2.21374396e+00, -1.26885524e+00, -1.92142197e+00,\n",
       "        7.82262614e-02, -2.53243322e+00, -2.34112040e+00,  1.65666476e+00,\n",
       "        4.13586691e-01, -3.12815749e+00, -3.14327001e+00, -3.58284661e+00,\n",
       "        5.20290158e-01, -1.77168350e+00, -1.76189538e+00, -1.99032886e+00,\n",
       "       -3.12396422e+00, -2.85766618e+00, -9.16820042e-01,  1.79531935e+00,\n",
       "       -1.66974762e+00, -2.81742243e+00, -1.60444777e+00, -1.68425308e+00,\n",
       "        2.04312837e+00,  1.61928208e+00, -2.82126245e+00, -1.71321615e+00,\n",
       "        1.92611958e+00,  2.27004839e+00,  1.00368368e+00, -4.61254335e+00,\n",
       "       -2.34633890e+00, -2.28403163e+00, -1.33125556e+00, -2.11516270e+00,\n",
       "        5.62985613e-01, -2.46512165e+00,  1.77881551e+00, -1.95976855e+00,\n",
       "       -2.52838605e+00,  1.65014736e+00,  1.94409341e+00,  3.29145636e-01,\n",
       "       -1.32628895e+00, -2.99092018e+00, -2.97495262e+00, -3.12355025e-01,\n",
       "       -3.46939085e-01, -4.10235819e+00, -1.60723880e+00, -3.16529859e+00,\n",
       "        8.18095230e-01, -1.54544920e+00, -1.88690103e+00, -3.12751636e+00,\n",
       "        1.61344833e+00, -4.10786252e+00, -9.94703812e-01,  2.02489312e+00,\n",
       "       -8.22289467e-01, -3.22678724e+00, -3.13881860e+00,  1.02447437e+00,\n",
       "       -2.47027517e+00,  1.64064828e+00, -1.22235610e+00, -2.47767360e+00,\n",
       "       -1.10677614e+00,  9.29994245e-01, -1.98450507e+00,  1.28073177e+00,\n",
       "       -7.53887154e-01,  1.27964806e+00, -2.79568194e+00, -6.09805524e-01,\n",
       "       -3.89065828e+00, -3.65428560e+00,  4.14834389e+00, -2.52406305e+00,\n",
       "        3.42938455e+00, -2.98461266e+00, -3.96022663e+00, -2.68986643e+00,\n",
       "        1.73984637e-01, -9.46959127e-01,  1.96178250e+00, -3.03865663e+00,\n",
       "       -5.75292326e-01,  2.11134212e+00, -2.13621330e+00, -2.44208773e+00,\n",
       "        1.74720352e+00, -1.93648131e+00,  1.52416033e+00, -1.33058985e+00,\n",
       "        1.37396141e+00, -3.59416463e+00, -1.92235269e+00,  1.95260268e+00,\n",
       "       -2.88792766e+00,  6.52197964e-01, -1.91781056e+00, -4.25270852e+00,\n",
       "       -3.38824570e+00, -1.20791195e+00, -1.04141802e+00,  1.79764211e+00,\n",
       "       -3.03630227e+00, -2.65547571e+00,  1.82074681e+00, -1.66998654e+00,\n",
       "       -3.82180200e+00,  1.69031926e-01, -2.17912166e+00, -1.81418124e+00,\n",
       "       -1.04873968e+00,  1.78357669e+00, -8.45332763e-01,  2.27005657e+00,\n",
       "       -7.69189766e-01, -1.81972634e+00, -2.09342807e+00, -2.24578843e+00,\n",
       "        2.08681883e-01, -2.42074131e+00, -1.07781839e+00, -3.02122600e+00,\n",
       "        1.73345724e+00, -1.45720376e+00,  1.34769878e+00, -3.26496977e+00,\n",
       "       -2.69471799e+00, -2.32534477e+00, -2.31030478e+00, -1.97460011e+00,\n",
       "       -3.51215610e+00, -2.84475785e+00, -2.24067026e+00,  1.00112009e+00,\n",
       "       -2.82859354e+00, -1.90315648e+00,  2.06347876e+00, -2.46808796e+00,\n",
       "       -3.05798434e+00, -6.90274839e-01, -1.73777738e+00,  1.25327801e+00,\n",
       "        6.59874115e-02, -2.08073385e+00, -1.73022971e+00,  2.88157014e+00,\n",
       "        3.19657240e+00, -2.88816783e+00,  1.76009338e+00,  1.97633682e+00])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_function(x_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c0bKCboN4Zxu"
   },
   "source": [
    "<h2><font color='Geen'> 8F: Implementing Platt Scaling to find P(Y==1|X)</font></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nMn7OEN94Zxw"
   },
   "source": [
    "Check this <a href='https://drive.google.com/open?id=133odBinMOIVb_rh_GQxxsyMRyW-Zts7a'>PDF</a>\n",
    "<img src='https://i.imgur.com/CAMnVnh.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e0n5EFkx4Zxz"
   },
   "source": [
    "## TASK F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t0HOqVJq4Zx1"
   },
   "source": [
    "\n",
    "> 4. Apply SGD algorithm with ($f_{cv}$, $y_{cv}$) and find the weight $W$ intercept $b$ ```Note: here our data is of one dimensional so we will have a one dimensional weight vector i.e W.shape (1,)``` \n",
    "\n",
    "> Note1: Don't forget to change the values of $y_{cv}$ as mentioned in the above image. you will calculate y+, y- based on data points in train data\n",
    "\n",
    "> Note2: the Sklearn's SGD algorithm doesn't support the real valued outputs, you need to use the code that was done in the `'Logistic Regression with SGD and L2'` Assignment after modifying loss function, and use same parameters that used in that assignment.\n",
    "<img src='https://i.imgur.com/zKYE9Oc.png'>\n",
    "if Y[i] is 1, it will be replaced with y+ value else it will replaced with y- value\n",
    "\n",
    "> 5. For a given data point from $X_{test}$, $P(Y=1|X) = \\frac{1}{1+exp(-(W*f_{test}+ b))}$ where ` `$f_{test}$ ```= decision_function(```$X_{test}$```)```, W and b will be learned as metioned in the above step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating Y+ and Y-\n",
    "Np, Nn = np.unique(y_train, return_counts=True)[1]\n",
    "Yp = (Np+1)/(Np+2)\n",
    "Yn = 1/(Nn+2)\n",
    "\n",
    "ycv_new = []\n",
    "\n",
    "#Converting 0s and 1s in Y_CV to Y+ or Y-\n",
    "for y in y_cv:\n",
    "    if y == 0:\n",
    "        ycv_new.append(Yn)\n",
    "    else:\n",
    "        ycv_new.append(Yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(dim):\n",
    "    ''' In this function, we will initialize our weights and bias'''\n",
    "    #initialize the weights to zeros array of (1,dim) dimensions\n",
    "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
    "    #initialize bias to zero\n",
    "    w = np.zeros_like(dim).reshape(1,-1)\n",
    "    b = 0\n",
    "\n",
    "    return w,b\n",
    "\n",
    "def sigmoid(z):\n",
    "    ''' In this function, we will return sigmoid of z'''\n",
    "    # compute sigmoid(z) and return\n",
    "    result = 1/(1+np.exp(-z))\n",
    "    return result\n",
    "\n",
    "def logloss(y_true,y_pred):\n",
    "    '''In this function, we will compute log loss '''\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    loss = -np.sum(y_true * np.log10(y_pred) + (1 - y_true) * np.log10(1 - y_pred))/len(y_true)\n",
    "    return loss\n",
    "\n",
    "def gradient_dw(x,y,w,b,alpha,N):\n",
    "    '''In this function, we will compute the gardient w.r.to w '''\n",
    "    dw = (x * (y- sigmoid((w@x)+b) )) - ((alpha/N)*w)\n",
    "    return dw\n",
    "\n",
    "def gradient_db(x,y,w,b):\n",
    "    '''In this function, we will compute gradient w.r.to b '''\n",
    "    db = y - sigmoid(w@x+b)\n",
    "    return db\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(X_train,y_train,epochs,alpha,eta0):\n",
    "    ''' In this function, we will implement logistic regression'''\n",
    "    train_loss,test_loss = [],[]\n",
    "    w,b = initialize_weights(X_train[0])\n",
    "    #print(\"weight is {}\".format(b))\n",
    "\n",
    "    N = len(X_train)\n",
    "    for epoch in tqdm(range(0,epochs)):\n",
    "        for x,y in zip(X_train.reshape(-1,1),y_train.reshape(-1,1)):\n",
    "            #print(x.shape)\n",
    "            #print(y.shape)\n",
    "            #print(w.shape)\n",
    "            #print(b)\n",
    "            gradw = gradient_dw(x,y,w,b,alpha,N)\n",
    "            gradb = gradient_db(x,y,w,b)\n",
    "            w += (eta0 * gradw)\n",
    "            b += (eta0 * gradb)\n",
    "       \n",
    "        trainloss = logloss(y_train, 1/(1+np.exp(-(w * decision_function(X_train) + b))))\n",
    "        train_loss.append(trainloss)\n",
    "        print(f\"Epoch {epoch+1}: Training loss: {trainloss}\")\n",
    "                \n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 1/50 [00:04<03:53,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training loss: 0.29867417569558563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|         | 2/50 [00:09<03:50,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Training loss: 0.2964083671148156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|         | 3/50 [00:14<03:47,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Training loss: 0.29422969313477015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|         | 4/50 [00:19<03:41,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Training loss: 0.2921353661082111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|         | 5/50 [00:24<03:35,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Training loss: 0.2901226858858137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|        | 6/50 [00:28<03:29,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Training loss: 0.2881890380678522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|        | 7/50 [00:33<03:25,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Training loss: 0.2863318921674281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|        | 8/50 [00:38<03:20,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Training loss: 0.2845487997017492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|        | 9/50 [00:43<03:15,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Training loss: 0.28283739222646265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|        | 10/50 [00:47<03:11,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Training loss: 0.28119537932662503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|       | 11/50 [00:52<03:05,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Training loss: 0.27962054657655405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|       | 12/50 [00:57<03:01,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Training loss: 0.27811075347956193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|       | 13/50 [01:02<02:57,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Training loss: 0.2766639313974079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|       | 14/50 [01:07<02:54,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Training loss: 0.27527808147822463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|       | 15/50 [01:12<02:49,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Training loss: 0.2739512725906818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|      | 16/50 [01:17<02:45,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Training loss: 0.27268163927122135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|      | 17/50 [01:21<02:39,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Training loss: 0.27146737969035917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|      | 18/50 [01:26<02:35,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Training loss: 0.27030675364326917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|      | 19/50 [01:31<02:30,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Training loss: 0.26919808056915456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|      | 20/50 [01:36<02:24,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Training loss: 0.2681397376032705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|     | 21/50 [01:41<02:20,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Training loss: 0.267130157664868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|     | 22/50 [01:45<02:14,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Training loss: 0.2661678275838017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|     | 23/50 [01:50<02:10,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Training loss: 0.2652512862680629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|     | 24/50 [01:55<02:05,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Training loss: 0.2643791229140615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|     | 25/50 [02:00<02:01,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Training loss: 0.263549975261099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|    | 26/50 [02:05<01:57,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Training loss: 0.2627625278911189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|    | 27/50 [02:10<01:54,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Training loss: 0.2620155105745157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|    | 28/50 [02:15<01:48,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Training loss: 0.2613076966625051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|    | 29/50 [02:20<01:42,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Training loss: 0.26063790152631294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|    | 30/50 [02:24<01:36,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Training loss: 0.2600049810432266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|   | 31/50 [02:29<01:31,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Training loss: 0.2594078301293614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|   | 32/50 [02:34<01:27,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Training loss: 0.2588453813188314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|   | 33/50 [02:39<01:22,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Training loss: 0.2583166033888669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|   | 34/50 [02:44<01:18,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Training loss: 0.2578205000303009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|   | 35/50 [02:49<01:14,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Training loss: 0.257356108562738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|  | 36/50 [02:54<01:09,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Training loss: 0.2569224986936313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|  | 37/50 [02:59<01:04,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Training loss: 0.25651877132041523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|  | 38/50 [03:04<00:58,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Training loss: 0.25614405737478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|  | 39/50 [03:08<00:53,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Training loss: 0.25579751670812656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|  | 40/50 [03:13<00:48,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Training loss: 0.2554783370171928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%| | 41/50 [03:18<00:43,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Training loss: 0.25518573280881746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%| | 42/50 [03:23<00:38,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Training loss: 0.254918944402781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%| | 43/50 [03:28<00:33,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Training loss: 0.2546772369716495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%| | 44/50 [03:32<00:28,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Training loss: 0.2544598996165352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%| | 45/50 [03:37<00:24,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Training loss: 0.25426624447768686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|| 46/50 [03:42<00:19,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Training loss: 0.2540956058788216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|| 47/50 [03:47<00:14,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Training loss: 0.25394733950411597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|| 48/50 [03:52<00:09,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Training loss: 0.2538208216067861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|| 49/50 [03:56<00:04,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Training loss: 0.25371544824819303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 50/50 [04:01<00:00,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Training loss: 0.2536306345664302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "weight, bias = train(np.array(ycv_new), y_cv, 50, 0.0001, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78138312]])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-328-6fa574c371d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mpredict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m  \u001b[0;34m-\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'w' is not defined"
     ]
    }
   ],
   "source": [
    "def pred(w,b, X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        z=np.dot(w,X[i])+b\n",
    "        if sigmoid(z) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
    "            predict.append(1)\n",
    "        else:\n",
    "            predict.append(0)\n",
    "    return np.array(predict)\n",
    "print(1-np.sum(y_train - pred(w,b,X_train))/len(X_train))\n",
    "print(1-np.sum(y_test  - pred(w,b,X_test))/len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.16439526])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oTY7z2bd4Zx2"
   },
   "source": [
    "__Note: in the above algorithm, the steps 2, 4 might need hyper parameter tuning, To reduce the complexity of the assignment we are excluding the hyerparameter tuning part, but intrested students can try that__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CM3odN1Z4Zx3"
   },
   "source": [
    "\n",
    "If any one wants to try other calibration algorithm istonic regression also please check these tutorials\n",
    "\n",
    "1. http://fa.bianp.net/blog/tag/scikit-learn.html#fn:1\n",
    "\n",
    "2. https://drive.google.com/open?id=1MzmA7QaP58RDzocB0RBmRiWfl7Co_VJ7\n",
    "\n",
    "3. https://drive.google.com/open?id=133odBinMOIVb_rh_GQxxsyMRyW-Zts7a\n",
    "\n",
    "4. https://stat.fandom.com/wiki/Isotonic_regression#Pool_Adjacent_Violators_Algorithm\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "8E&F_LR_SVM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
